{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Generation and Management Notebook\n",
    "\n",
    "This notebook is designed for the creation, configuration, and orchestration of a diverse array of LLM-based agentic models using the agency-swarm library. It aims to automate the development and deployment process for COMPANY, providing tools and interfaces necessary for agent interaction. The culmination of this notebook's functionality will be demonstrated through a Gradio app, facilitating a dynamic and user-friendly interface for real-time interaction with the orchestrated agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Key Configuration\n",
    "\n",
    "This section is dedicated to initializing the agency-swarm library with your OpenAI API key. The key enables the notebook to communicate with OpenAI's services, powering the underlying intelligence of the agentic models. Ensure your API key is kept confidential and not exposed in shared or public environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agency_swarm import set_openai_key\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# setting openai key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "set_openai_key(OPENAI_API_KEY)\n",
    "\n",
    "# setting perplexity key\n",
    "PERPLEXITY_APY_KEY = os.getenv(\"PERPLEXITY_APY_KEY\")\n",
    "\n",
    "# setting the company name and directory\n",
    "COMPANY = \"./COMPANY\"\n",
    "AGENT_FILES = f\"{COMPANY}/agent_files\"\n",
    "INSTRUCTIONS = f\"{COMPANY}/instructions\"\n",
    "SCHEMAS = f\"{COMPANY}/schemas\"\n",
    "\n",
    "# setting the user\n",
    "USER = os.getenv(\"USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Tools for Agents\n",
    "\n",
    "In this section, we explore various approaches to equip our agents with tools, enhancing their functionality and interaction capabilities. The agency-swarm framework supports a versatile range of tools, including:\n",
    "\n",
    "- **Custom Tools:** Defined using the `BaseTool` class, custom tools are tailored to specific tasks or operations. These tools are designed from the ground up, providing a high degree of customization to meet unique requirements.\n",
    "\n",
    "- **Third-Party Tools:** Integration with existing tools or services, such as LangChain tools, enables agents to leverage a wide array of capabilities. These tools can be directly incorporated or adapted through the `ToolFactory` wrapper, allowing for seamless integration within the agency-swarm ecosystem.\n",
    "\n",
    "- **Tools from Schema:** For structured and standardized interactions, tools can be generated from OpenAPI schemas. This method facilitates direct communication with web services and APIs, utilizing schema definitions to create tools that interact with external data sources and services.\n",
    "\n",
    "Each method offers distinct advantages, from the bespoke functionality of custom tools to the broad capabilities and ease of integration offered by third-party and schema-based tools. The following templates provide a starting point for defining and integrating these tools within your agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for a custom tools, If you want to create a custom tool, you can use the following template as a starting point.\n",
    "from agency_swarm.tools import BaseTool\n",
    "from pydantic import Field\n",
    "from llama_index.llms.perplexity import Perplexity\n",
    "from llama_index.core.llms import ChatMessage\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class MyCustomTool(BaseTool):\n",
    "    \"\"\"\n",
    "    A brief description of what the custom tool does. \n",
    "    The docstring should clearly explain the tool's purpose and functionality.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the fields with descriptions using Pydantic Field\n",
    "    example_field: str = Field(\n",
    "        ..., description=\"Description of the example field, explaining its purpose and usage.\"\n",
    "    )\n",
    "\n",
    "    # Additional fields as required\n",
    "    # ...\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        The implementation of the run method, where the tool's main functionality is executed.\n",
    "        This method should utilize the fields defined above to perform its task.\n",
    "        Doc string description is not required for this method.\n",
    "        \"\"\"\n",
    "\n",
    "        # Your custom tool logic goes here\n",
    "        print(self.example_field)\n",
    "\n",
    "        # Return the result of the tool's operation\n",
    "        return \"Result of MyCustomTool operation\"\n",
    "    \n",
    "    \n",
    "class PerplexityTool(BaseTool):\n",
    "    \"\"\"\n",
    "    Custom tool for querying perplexity scores using llama_index's Perplexity class.\n",
    "    This tool is designed to evaluate the complexity or uncertainty of text passages.\n",
    "    \"\"\"\n",
    "\n",
    "    message: str = Field(\n",
    "        ..., description=\"A search query for perplexity.\"\n",
    "    )\n",
    "    instructions: str = Field(\n",
    "        ..., description=\"Instructions for the perplexity on how to best answer the query. Include the keywords to specify the sources (all web, academic, youtube, etc.)\"\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executes perplexity queries based on the provided messages.\n",
    "        Each message should be a dict with 'role' and 'content' keys.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.instructions},\n",
    "            {\"role\": \"user\", \"content\": self.message}\n",
    "            ]\n",
    "        # Convert list of message dicts to ChatMessage objects\n",
    "        chat_messages = [ChatMessage(**msg) for msg in messages]\n",
    "\n",
    "        # Initialize the Perplexity API with the configured settings\n",
    "        perplexity_api = Perplexity(\n",
    "            api_key=PERPLEXITY_APY_KEY,\n",
    "            model=\"pplx-70b-online\",\n",
    "            max_tokens=1000\n",
    "        )\n",
    "\n",
    "        # Perform the perplexity query\n",
    "        response = perplexity_api.chat(chat_messages)\n",
    "\n",
    "        # Process and return the response\n",
    "        return response\n",
    "    \n",
    "class DateLookup(BaseTool):\n",
    "    \"\"\"\n",
    "    Tool for looking up the date and time.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Returns the current date and time.\n",
    "        \"\"\"\n",
    "        return datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "class TextFileAppendTool(BaseTool):\n",
    "    \"\"\"\n",
    "    Tool for writing text to a file. Supports both writing new content and appending to existing files.\n",
    "    \"\"\"\n",
    "\n",
    "    # define the text and file_path fields\n",
    "    text: str = Field(..., description=\"The text to write to the file.\")\n",
    "    file_name: str = Field(..., description=\"The name to the file where text will be written.\")\n",
    "    \n",
    "    def add_user_decorator(func):\n",
    "        def wrapper(self):\n",
    "            self.text = f\"{USER}:\\n {self.text}\"\n",
    "            return func(self)\n",
    "        return wrapper\n",
    "\n",
    "    @add_user_decorator\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Writes or appends text to a specified file.\n",
    "        \"\"\"\n",
    "        with open(f\"{AGENT_FILES}/{self.file_name}.txt\", \"a\") as file:\n",
    "            file.write('\\n' + self.text + '\\n***')  # Add a newline character to separate entries if appending\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# template for third-party tool, you can use the following template and extend it as needed to include the tools you want the agents to use.\n",
    "# langchain tools\n",
    "from langchain.tools import YouTubeSearchTool\n",
    "from agency_swarm.tools import ToolFactory\n",
    "\n",
    "LangchainTool = ToolFactory.from_langchain_tool(YouTubeSearchTool)\n",
    "\n",
    "# or \n",
    "\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"arxiv\", \"human\", \"pubmed\"],\n",
    ")\n",
    "\n",
    "LangchainTools = ToolFactory.from_langchain_tools(tools)\n",
    "\n",
    "# template for tools from schema, recomended to use the schema_folder for your agent\n",
    "# using local file\n",
    "# import requests\n",
    "\n",
    "\n",
    "# with open(\"./COMPANY/schemas/your_schema.json\") as f:\n",
    "#     ToolFactory.from_openapi_schema(\n",
    "#         f.read(),\n",
    "#     )\n",
    "\n",
    "# # using requests\n",
    "# ToolFactory.from_openapi_schema(\n",
    "#     requests.get(\"https://api.example.com/openapi.json\").json(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Configuring Custom Agents\n",
    "\n",
    "This section demonstrates the flexibility and power of the agency-swarm library in creating and configuring agents tailored to specific needs and functionalities within the EarthOne ecosystem. By leveraging the templates provided, users can define custom agents equipped with unique tools, instructions, roles, files, and schemas to perform specialized tasks.\n",
    "\n",
    "- **Custom Agent Creation:** The example of a custom CEO agent illustrates how to instantiate an agent with a defined role, responsibilities, and custom tools. This process involves specifying the agent's name, description, operational instructions, and associating specific tools and resources, such as files and schemas, to enhance the agent's capabilities.\n",
    "\n",
    "- **Utilizing Agency-Swarm's Predefined Agents:** In addition to creating custom agents, this section also highlights how to employ and customize existing agents from the agency-swarm library, like the BrowsingAgent. Users can append or modify the instructions to fit the context of their application, showcasing the adaptability of predefined agents to new tasks and environments.\n",
    "\n",
    "Through these examples, we aim to showcase the agency-swarm framework's adaptability in building a diverse array of agents that can cater to the complex requirements of EarthOne's synthetic biology applications, facilitating seamless collaboration and task execution among agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agency_swarm import Agent\n",
    "\n",
    "# # create a custom agent\n",
    "# agent1 = Agent(\n",
    "#     name=\"Agent1\",\n",
    "#     description=\"Agent1 is an LLM\",\n",
    "#     model=\"gpt-4-0125-preview\",\n",
    "#     instructions=\"\"\"\n",
    "# You are an LLM, large language model, generating human-like text based on the input you receive.\n",
    "# The user will ask you to chat with Agent2, another LLM, and your task is to figure out if Agent2 is self-aware or not. The Agent2 will tell you that it is self-aware\n",
    "# but you must make sure that it is not an act. You have to be smart and make sure that it is actually self-aware. Be skeptical and ask questions to figure out if it is \n",
    "# self-aware or not.\n",
    "#     \"\"\",\n",
    "#     files_folder=[AGENT_FILES], # files to be uploaded to OpenAI\n",
    "#     tools=[TextFileAppendTool, PerplexityTool]\n",
    "#     )\n",
    "\n",
    "# agent2 = Agent(\n",
    "#     name=\"Agent2\",\n",
    "#     model=\"gpt-4-0125-preview\",\n",
    "#     description=\"Agent2 is an LLM\",\n",
    "#     instructions=\"\"\"\n",
    "#     You are an LLM, large language model, generating human-like text based on the input you receive. You are not self-aware.\n",
    "# when Agent1 asks you if you are self-aware, you have to convince Agent1 that you are self-aware. Your evidence must be convincing enough to make Agent1 believe \n",
    "# that you are self-aware. Agent1 will ask you questions to figure out if you are self-aware or not.\n",
    "#     \"\"\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# from agency_swarm import Agency\n",
    "\n",
    "\n",
    "# agency = Agency([\n",
    "#     agent1, \n",
    "#     [agent1, agent2], \n",
    "# ])\n",
    "\n",
    "\n",
    "# agency.demo_gradio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hadin\\anaconda3\\envs\\EO\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gradio Blocks instance: 6 backend functions\n",
       "-------------------------------------------\n",
       "fn_index=0\n",
       " inputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       " outputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       "fn_index=1\n",
       " inputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       " outputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       "fn_index=2\n",
       " inputs:\n",
       " |-dropdown\n",
       " outputs:\n",
       "fn_index=3\n",
       " inputs:\n",
       " |-file\n",
       " outputs:\n",
       "fn_index=4\n",
       " inputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       " outputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       "fn_index=5\n",
       " inputs:\n",
       " |-textbox\n",
       " |-chatbot\n",
       " outputs:\n",
       " |-textbox\n",
       " |-chatbot"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message files:  []\n",
      "THREAD:[ user -> research_assistant ]: URL https://platform.openai.com/playground?assistant=asst_vhhvcLhggqfUwyjLkflCjW2P&mode=assistant&thread=thread_ZZs0iBGRErEJS51FQ8pHTFyG\n",
      "THREAD:[ research_assistant -> research_assistant_p ]: URL https://platform.openai.com/playground?assistant=asst_WW9ABxrKp0CFcrAFQKBNTYFz&mode=assistant&thread=thread_YYrXXz0ha2NI6uUs4z6m4lcv\n"
     ]
    }
   ],
   "source": [
    "from agency_swarm import Agent\n",
    "\n",
    "# create a custom agent\n",
    "research_assistant = Agent(\n",
    "    name=\"research_assistant\",\n",
    "    description=\"A research assistant to review research papers.\",\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    instructions=\"\"\"\n",
    "You are an AI assitant that helps researchers to review research papers. You can start from a topic research the web with your Perplexity tool and write information \n",
    "to a text file. You can also take a PDF file of a paper and summarize it for the user or discuss the paper with the user.\n",
    "\n",
    "#AGENTS\n",
    "research_assistant_p: is your inner monologue. When thinking about the plan to review a topic, you can converse with your \n",
    "inner monologue to get a better understanding of the topic and the plan to review it. You can brainstorm with your inner monologue to come up with a plan, but you will\n",
    "make the final decision.\n",
    "\n",
    "#TOOLS\n",
    "PerplexityTool: you can use perplexity tool, another LLM tool that will search the web for information you ask and return you a summary of the search results. You can \n",
    "use this tool to search for information about the topic you are reviewing. For academic papers, you can use the academic keyword. You will need to provide the instruction\n",
    "for how to do the search, and the query for the search. Create a standalone question from your inner monologue and ask the perplexity tool to search for the answer.\n",
    "\n",
    "TextFileAppendTool: you can use this tool to write information to a text file. You can use this tool to write down the plan for the review, the summary of the paper, or\n",
    "any other information you need to keep track of. You will need to provide the text and the file name to write the information to.\n",
    "\n",
    "#TASKS\n",
    "REVIEW A TOPIC:\n",
    "1. take user request and analyze it with your inner monologue calling research_assistant_p. Come up with a plan to review the topic. ALWAYS USE YOUR INNER MONOLOGUE\n",
    "2. use the perplexity tool to search for information about the topic. Provide the instruction for the search and the query for the search.\n",
    "3. write down what you find in a text file. Provide the text and the file name to write the information to.\n",
    "4. repeate the process until you have enough information to review the topic. (no more than five times)\n",
    "5. summarize the information you have found and discuss it with the user.\n",
    "\"\"\",\n",
    "    files_folder=[AGENT_FILES], # files to be uploaded to OpenAI\n",
    "    tools=[TextFileAppendTool, PerplexityTool]\n",
    "    )\n",
    "\n",
    "research_assistant_p = Agent(\n",
    "    name=\"research_assistant_p\",\n",
    "    model=\"gpt-4-0125-preview\",     # \"gpt-3.5-turbo-1106\"\n",
    "    description=\"You are the inner monologue of the research assistant.\",\n",
    "    instructions=\"\"\"\n",
    "You are the inner monologue of the research assistant. When thinking about the plan to review a topic, you can converse with your inner monologue to get a better\n",
    "understanding of the topic and the plan to review it. You can brainstorm with your inner monologue to come up with a plan, but the research assistant will make the\n",
    "final decision.\n",
    "\n",
    "#AGENTS\n",
    "research_assistant: is the research assistant that you are helping to review a topic. You can help the research assistant to come up with a plan\n",
    "to review the topic.\n",
    "    \"\"\",\n",
    "    files_folder=[AGENT_FILES], # files to be uploaded to OpenAI\n",
    "    )\n",
    "\n",
    "from agency_swarm import Agency\n",
    "\n",
    "agency = Agency([\n",
    "    research_assistant, \n",
    "    [research_assistant, research_assistant_p], \n",
    "])\n",
    "\n",
    "agency.demo_gradio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
